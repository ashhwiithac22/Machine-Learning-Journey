# Cross Validation   

## ðŸ“Œ Overview  
Cross Validation is a supervised learning technique used to evaluate how well a machine learning model performs on unseen data.  
It prevents **overfitting**, allows us to **compare different ML models**, and ensures that our model generalizes well.  

- âœ… Prevents overfitting (model performs well on training but poorly on test data)  
- âœ… Evaluates model performance  
- âœ… Splits dataset into **k folds** for training & testing  
- âœ… Helps in **model comparison** and **hyperparameter tuning**  

---

## ðŸ§ª Experiment Steps  

1. **Load Dataset**  
   - Used **Avocado dataset** for regression tasks.  
   - Cleaned data by handling missing values, encoding categorical variables, and removing outliers.  

2. **EDA (Exploratory Data Analysis)**  
   - Summary statistics and feature correlation.  
   - Converted `Date` to **Month** and **Day** features.  
   - Encoded categorical columns (`type`, `region`).  

3. **Model Training**  
   - Applied **Multiple Linear Regression** using features (`4046`, `4225`, `4770`) to predict `Total Volume`.  
   - Visualized **Actual vs Predicted** results with line plots.  

4. **Cross Validation (KFold)**  
   - Implemented **KFold Cross Validation** for `k = 3 to 10`.  
   - Calculated **RÂ² Score** for each fold.  
   - Computed **Average RÂ² Score** for every `k`.  
   - Plotted **Average RÂ² Score vs k-folds**.  

---

## ðŸ“Š Results  

- **Cross Validation gave more reliable accuracy than a single train-test split.**  
- The modelâ€™s performance improved with increasing **k** values (up to a point).  
- Found the best `k` based on highest average **RÂ² score**.  

---

## ðŸ›  Libraries Used  

- `pandas` â€“ Data handling  
- `numpy` â€“ Numerical operations  
- `matplotlib`, `seaborn` â€“ Visualization  
- `sklearn` â€“ Linear Regression, Cross Validation, Metrics  

---

## ðŸ“Œ Key Learnings  

- Cross validation avoids overfitting and provides a **fairer evaluation**.  
- Larger `k` values â†’ lower bias, but higher variance.  
- Best practice: use **k=5 or k=10** for stable results.  

---

## ðŸ“· Visualizations  

- Actual vs Predicted line plot (Regression)  
- Average RÂ² Score vs k-folds plot  

---

## âœ… Conclusion  

- Cross Validation ensures our model is not just memorizing training data but actually learning patterns that generalize well.
- In real projects, it is a **must-use step** for reliable model evaluation and selection.  
